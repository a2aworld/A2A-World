{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2A World Platform Demo and Setup Guide\n",
    "\n",
    "This Jupyter notebook provides a comprehensive guide to setting up and demonstrating the A2A World Platform. The A2A World Platform is a sophisticated system for multidisciplinary data analysis, pattern discovery, and agent-based processing of cultural and mythological data.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Environment Setup](#Environment-Setup)\n",
    "2. [Dependencies Installation](#Dependencies-Installation)\n",
    "3. [Configuration Guide](#Configuration-Guide)\n",
    "4. [Database Setup](#Database-Setup)\n",
    "5. [Agent System Demonstration](#Agent-System-Demonstration)\n",
    "6. [Key Functionality Demos](#Key-Functionality-Demos)\n",
    "7. [Troubleshooting](#Troubleshooting)\n",
    "8. [Complete Configuration Reference](#Complete-Configuration-Reference)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Docker and Docker Compose\n",
    "- Git\n",
    "- Jupyter Notebook\n",
    "\n",
    "## System Architecture Overview\n",
    "\n",
    "The A2A World Platform consists of:\n",
    "\n",
    "- **FastAPI Backend**: REST API server\n",
    "- **Next.js Frontend**: React-based dashboard\n",
    "- **PostgreSQL + PostGIS**: Spatial database\n",
    "- **Redis**: Caching and session storage\n",
    "- **NATS**: Agent messaging system\n",
    "- **Consul**: Service discovery\n",
    "- **Ollama**: Local LLM inference\n",
    "- **Multiple Agent Types**: Data processing, validation, pattern discovery\n",
    "\n",
    "Let's begin the setup process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, let's set up the development environment. We'll clone the repository and navigate to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the A2A World Platform repository\n",
    "# Note: This cell assumes you're running in a directory where you want to clone the repo\n",
    "# If the repo is already cloned, skip this step\n",
    "\n",
    "# !git clone https://github.com/your-org/a2a-world-platform.git\n",
    "# %cd a2a-world-platform\n",
    "\n",
    "# Verify we're in the correct directory\n",
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Contents: {os.listdir('.')}\")\n",
    "\n",
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies Installation\n",
    "\n",
    "The A2A World Platform has several dependency sets:\n",
    "- Python backend dependencies (FastAPI, databases, ML libraries)\n",
    "- Node.js frontend dependencies (Next.js, React, mapping libraries)\n",
    "- Docker services (PostgreSQL, Redis, NATS, etc.)\n",
    "\n",
    "Let's install the Python dependencies first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "# This installs all required packages for the backend and agents\n",
    "\n",
    "# First, let's check if requirements.txt exists\n",
    "import os\n",
    "if os.path.exists('requirements.txt'):\n",
    "    print(\"Found requirements.txt\")\n",
    "    # Install dependencies\n",
    "    # !pip install -r requirements.txt\n",
    "    print(\"Dependencies installed successfully\")\n",
    "else:\n",
    "    print(\"requirements.txt not found. Please ensure you're in the correct project directory.\")\n",
    "\n",
    "# Verify key packages are available\n",
    "try:\n",
    "    import fastapi\n",
    "    import sqlalchemy\n",
    "    import nats\n",
    "    import geopandas\n",
    "    import torch\n",
    "    print(\"✓ Core dependencies verified\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Missing dependency: {e}\")\n",
    "    print(\"Please run: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Node.js dependencies for the frontend\n",
    "# This requires Node.js and npm to be installed\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Check if we're in the frontend directory\n",
    "if os.path.exists('frontend/package.json'):\n",
    "    os.chdir('frontend')\n",
    "    \n",
    "    # Install dependencies\n",
    "    try:\n",
    "        result = subprocess.run(['npm', 'install'], capture_output=True, text=True, check=True)\n",
    "        print(\"✓ Frontend dependencies installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"✗ Failed to install frontend dependencies: {e}\")\n",
    "        print(\"Please ensure Node.js and npm are installed\")\n",
    "    \n",
    "    os.chdir('..')\n",
    "else:\n",
    "    print(\"Frontend directory not found. Please check project structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Guide\n",
    "\n",
    "The A2A World Platform requires several configuration files and environment variables. Let's set up the basic configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file from template\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists('.env.example') and not os.path.exists('.env'):\n",
    "    shutil.copy('.env.example', '.env')\n",
    "    print(\"✓ Created .env file from template\")\n",
    "    print(\"Please edit .env with your specific configuration values\")\n",
    "elif os.path.exists('.env'):\n",
    "    print(\"✓ .env file already exists\")\n",
    "else:\n",
    "    print(\"✗ .env.example not found. Please check project structure.\")\n",
    "\n",
    "# Display current .env configuration (with sensitive data masked)\n",
    "if os.path.exists('.env'):\n",
    "    print(\"\\nCurrent .env configuration:\")\n",
    "    with open('.env', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                key = line.split('=')[0]\n",
    "                if 'PASSWORD' in key or 'SECRET' in key:\n",
    "                    print(f\"{key}=***masked***\")\n",
    "                else:\n",
    "                    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Environment Variables\n",
    "\n",
    "Here are the key environment variables you need to configure:\n",
    "\n",
    "#### Database Configuration\n",
    "- `DATABASE_URL`: PostgreSQL connection string\n",
    "- `POSTGRES_SERVER`, `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`: Database credentials\n",
    "\n",
    "#### Messaging and Services\n",
    "- `REDIS_URL`: Redis connection URL\n",
    "- `NATS_URL`: NATS messaging server URL\n",
    "- `CONSUL_HOST`, `CONSUL_PORT`: Consul service discovery\n",
    "\n",
    "#### API Configuration\n",
    "- `SECRET_KEY`: JWT signing key (minimum 32 characters)\n",
    "- `API_V1_STR`: API version prefix\n",
    "\n",
    "#### External Services\n",
    "- `OLLAMA_URL`: Local LLM inference server\n",
    "- `SMTP_*`: Email configuration (optional)\n",
    "\n",
    "Let's validate the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate configuration\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Required configuration checks\n",
    "required_vars = [\n",
    "    'DATABASE_URL',\n",
    "    'REDIS_URL',\n",
    "    'NATS_URL',\n",
    "    'SECRET_KEY',\n",
    "    'OLLAMA_URL'\n",
    "]\n",
    "\n",
    "missing_vars = []\n",
    "for var in required_vars:\n",
    "    if not os.getenv(var):\n",
    "        missing_vars.append(var)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"✗ Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please update your .env file\")\n",
    "else:\n",
    "    print(\"✓ All required environment variables are set\")\n",
    "\n",
    "# Validate SECRET_KEY length\n",
    "secret_key = os.getenv('SECRET_KEY', '')\n",
    "if len(secret_key) < 32:\n",
    "    print(f\"✗ SECRET_KEY too short ({len(secret_key)} chars). Minimum 32 characters required.\")\n",
    "else:\n",
    "    print(\"✓ SECRET_KEY length is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "\n",
    "The A2A World Platform uses PostgreSQL with PostGIS extension for spatial data. Let's set up the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database initialization\n",
    "# This section demonstrates how to set up the database using Docker Compose\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"Starting database services with Docker Compose...\")\n",
    "print(\"This will start PostgreSQL, Redis, NATS, and Consul services\")\n",
    "\n",
    "# Start only the database services first\n",
    "try:\n",
    "    # Start database services\n",
    "    result = subprocess.run([\n",
    "        'docker-compose', 'up', '-d', \n",
    "        'postgres', 'redis', 'nats', 'consul'\n",
    "    ], capture_output=True, text=True, check=True)\n",
    "    \n",
    "    print(\"✓ Database services started successfully\")\n",
    "    \n",
    "    # Wait for services to be healthy\n",
    "    print(\"Waiting for services to be ready...\")\n",
    "    time.sleep(30)\n",
    "    \n",
    "    # Check service health\n",
    "    result = subprocess.run([\n",
    "        'docker-compose', 'ps'\n",
    "    ], capture_output=True, text=True, check=True)\n",
    "    \n",
    "    print(\"Service status:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"✗ Failed to start database services: {e}\")\n",
    "    print(\"Please ensure Docker and Docker Compose are installed and running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database schema\n",
    "# Run the database migration scripts\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if database schemas exist\n",
    "schema_dir = Path('database/schemas')\n",
    "if schema_dir.exists():\n",
    "    schemas = list(schema_dir.glob('*.sql'))\n",
    "    schemas.sort()  # Ensure proper order\n",
    "    \n",
    "    print(f\"Found {len(schemas)} schema files:\")\n",
    "    for schema in schemas:\n",
    "        print(f\"  - {schema.name}\")\n",
    "    \n",
    "    # Note: In a real setup, these would be executed via the init script\n",
    "    # For demo purposes, we'll show the schema structure\n",
    "    \n",
    "    print(\"\\nDatabase schema includes:\")\n",
    "    print(\"- Users table for authentication\")\n",
    "    print(\"- Datasets table for uploaded data\")\n",
    "    print(\"- System logs for monitoring\")\n",
    "    print(\"- PostGIS extensions for spatial data\")\n",
    "    print(\"- Agent system tables\")\n",
    "    print(\"- Pattern discovery tables\")\n",
    "    print(\"- Cultural data tables\")\n",
    "    \n",
    "else:\n",
    "    print(\"✗ Database schema directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent System Demonstration\n",
    "\n",
    "The A2A World Platform features a sophisticated multi-agent system. Let's demonstrate a simplified agent setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Agent System Demo\n",
    "# This demonstrates the basic agent architecture\n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the agents directory to Python path\n",
    "sys.path.append('agents')\n",
    "\n",
    "try:\n",
    "    from agents.core.base_agent import BaseAgent\n",
    "    from agents.core.config import AgentConfig\n",
    "    \n",
    "    print(\"✓ Agent system imports successful\")\n",
    "    \n",
    "    # Create a demo agent configuration\n",
    "    config = AgentConfig(\n",
    "        agent_id=\"demo-agent-001\",\n",
    "        agent_type=\"demo\",\n",
    "        nats_url=\"nats://localhost:4222\",\n",
    "        consul_host=\"localhost\",\n",
    "        consul_port=8500,\n",
    "        log_level=\"INFO\"\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Demo agent configuration created\")\n",
    "    print(f\"Agent ID: {config.agent_id}\")\n",
    "    print(f\"Agent Type: {config.agent_type}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Failed to import agent system: {e}\")\n",
    "    print(\"Please ensure all dependencies are installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate agent capabilities\n",
    "# Show different types of agents in the system\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# List available agent types\n",
    "agents_dir = Path('agents')\n",
    "agent_types = []\n",
    "\n",
    "if agents_dir.exists():\n",
    "    # Core agents\n",
    "    if (agents_dir / 'core').exists():\n",
    "        agent_types.append('Base Agent System')\n",
    "    \n",
    "    # Parser agents\n",
    "    if (agents_dir / 'parsers').exists():\n",
    "        agent_types.extend([\n",
    "            'KML Parser Agent',\n",
    "            'Data Processor Agents (Text, CSV, GeoJSON, KML)'\n",
    "        ])\n",
    "    \n",
    "    # Discovery agents\n",
    "    if (agents_dir / 'discovery').exists():\n",
    "        agent_types.extend([\n",
    "            'Pattern Discovery Agent',\n",
    "            'Archaeoastronomy Agent',\n",
    "            'Artistic Motif Agent',\n",
    "            'Cognitive Psychology Agent',\n",
    "            'Environmental Mythology Agent',\n",
    "            'Mythological Geography Agent',\n",
    "            'MARL Agents'\n",
    "        ])\n",
    "    \n",
    "    # Validation agents\n",
    "    if (agents_dir / 'validation').exists():\n",
    "        agent_types.extend([\n",
    "            'Multi-layered Validation Agent',\n",
    "            'Consensus Validation Agent',\n",
    "            'Cultural Validation Agent',\n",
    "            'Ethical Validation Agent',\n",
    "            'Statistical Validation Agent'\n",
    "        ])\n",
    "    \n",
    "    # XAI agents\n",
    "    if (agents_dir / 'xai').exists():\n",
    "        agent_types.append('Narrative XAI Agent')\n",
    "    \n",
    "    # Monitoring and notification\n",
    "    if (agents_dir / 'monitoring').exists():\n",
    "        agent_types.append('Monitor Agent')\n",
    "    if (agents_dir / 'notification').exists():\n",
    "        agent_types.append('Email Notification Agent')\n",
    "\n",
    "print(\"Available Agent Types in A2A World Platform:\")\n",
    "for i, agent_type in enumerate(agent_types, 1):\n",
    "    print(f\"{i}. {agent_type}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(agent_types)} agent types\")\n",
    "print(\"\\nEach agent type specializes in different aspects of multidisciplinary analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Functionality Demos\n",
    "\n",
    "Let's demonstrate some key functionalities of the A2A World Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing Demo\n",
    "# Demonstrate text processing capabilities for mythological texts\n",
    "\n",
    "try:\n",
    "    # Import text processing components\n",
    "    sys.path.append('agents/parsers/data_processors')\n",
    "    \n",
    "    # Sample mythological text\n",
    "    sample_text = \"\"\"\n",
    "    In the ancient myths of the Hopi people, the kachinas are spirit beings \n",
    "    that act as intermediaries between humans and the gods. These supernatural \n",
    "    entities are believed to bring rain, fertility, and prosperity to the tribes.\n",
    "    The kachinas are often represented in ceremonies and artwork, symbolizing \n",
    "    the connection between the physical and spiritual worlds.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Sample Text Processing:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(sample_text.strip())\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic text analysis\n",
    "    import re\n",
    "    \n",
    "    # Word count\n",
    "    words = re.findall(r'\\b\\w+\\b', sample_text)\n",
    "    print(f\"Word count: {len(words)}\")\n",
    "    \n",
    "    # Unique words\n",
    "    unique_words = set(words)\n",
    "    print(f\"Unique words: {len(unique_words)}\")\n",
    "    \n",
    "    # Key terms extraction (simple)\n",
    "    key_terms = [word.lower() for word in words if len(word) > 4]\n",
    "    print(f\"Potential key terms: {list(set(key_terms))[:10]}\")\n",
    "    \n",
    "    print(\"\\n✓ Text processing demo completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Text processing demo failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Demo\n",
    "# Demonstrate clustering capabilities for pattern discovery\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Generate sample geospatial data (representing archaeological sites)\n",
    "    np.random.seed(42)\n",
    "    n_sites = 100\n",
    "    \n",
    "    # Create synthetic data\n",
    "    sites_data = {\n",
    "        'latitude': np.random.uniform(30, 50, n_sites),\n",
    "        'longitude': np.random.uniform(-120, -80, n_sites),\n",
    "        'artifact_density': np.random.uniform(0, 100, n_sites),\n",
    "        'cultural_significance': np.random.uniform(0, 10, n_sites)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sites_data)\n",
    "    \n",
    "    print(\"Sample Archaeological Sites Data:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nTotal sites: {len(df)}\")\n",
    "    \n",
    "    # Prepare data for clustering\n",
    "    features = ['latitude', 'longitude', 'artifact_density', 'cultural_significance']\n",
    "    X = df[features]\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    n_clusters = 4\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Add cluster labels to dataframe\n",
    "    df['cluster'] = clusters\n",
    "    \n",
    "    print(f\"\\nClustering Results:\")\n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(\"Cluster sizes:\")\n",
    "    print(df['cluster'].value_counts().sort_index())\n",
    "    \n",
    "    # Calculate cluster centers\n",
    "    centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "    centers_df = pd.DataFrame(centers, columns=features)\n",
    "    print(\"\\nCluster Centers:\")\n",
    "    print(centers_df)\n",
    "    \n",
    "    print(\"\\n✓ Clustering demo completed\")\n",
    "    print(\"This demonstrates how the platform can identify patterns in spatial data\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Clustering demo failed - missing dependencies: {e}\")\n",
    "    print(\"Please install scikit-learn, pandas, numpy, matplotlib\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Clustering demo failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Demo\n",
    "# Demonstrate statistical validation capabilities\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy import stats\n",
    "    import pingouin as pg\n",
    "    \n",
    "    # Generate sample validation data\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate hypothesis testing data\n",
    "    # Group A: Sites with certain cultural features\n",
    "    # Group B: Sites without those features\n",
    "    \n",
    "    group_a_scores = np.random.normal(75, 10, 50)  # Higher significance scores\n",
    "    group_b_scores = np.random.normal(65, 12, 50)  # Lower significance scores\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(group_a_scores, group_b_scores)\n",
    "    \n",
    "    print(\"Statistical Validation Demo:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Group A mean significance: {group_a_scores.mean():.2f}\")\n",
    "    print(f\"Group B mean significance: {group_b_scores.mean():.2f}\")\n",
    "    print(f\"T-statistic: {t_stat:.3f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"✓ Significant difference detected (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"✗ No significant difference detected\")\n",
    "    \n",
    "    # Effect size calculation\n",
    "    cohens_d = (group_a_scores.mean() - group_b_scores.mean()) / \\\n",
    "               np.sqrt((group_a_scores.var() + group_b_scores.var()) / 2)\n",
    "    \n",
    "    print(f\"\\nEffect size (Cohen's d): {cohens_d:.3f}\")\n",
    "    \n",
    "    if abs(cohens_d) > 0.8:\n",
    "        print(\"Large effect size\")\n",
    "    elif abs(cohens_d) > 0.5:\n",
    "        print(\"Medium effect size\")\n",
    "    else:\n",
    "        print(\"Small effect size\")\n",
    "    \n",
    "    print(\"\\n✓ Statistical validation demo completed\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Validation demo failed - missing dependencies: {e}\")\n",
    "    print(\"Please install scipy, pingouin, numpy, pandas\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Validation demo failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "Common issues and their solutions when setting up the A2A World Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting utilities\n",
    "# Functions to diagnose common issues\n",
    "\n",
    "import subprocess\n",
    "import socket\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def check_service_port(host, port, service_name):\n",
    "    \"\"\"Check if a service is running on a specific port\"\"\"\n",
    "    try:\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        sock.settimeout(5)\n",
    "        result = sock.connect_ex((host, port))\n",
    "        sock.close()\n",
    "        if result == 0:\n",
    "            return f\"✓ {service_name} is running on {host}:{port}\"\n",
    "        else:\n",
    "            return f\"✗ {service_name} is not accessible on {host}:{port}\"\n",
    "    except Exception as e:\n",
    "        return f\"✗ Error checking {service_name}: {e}\"\n",
    "\n",
    "def check_docker_services():\n",
    "    \"\"\"Check status of Docker services\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run([\n",
    "            'docker-compose', 'ps'\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError:\n",
    "        return \"✗ Docker Compose not available or no services running\"\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "print(\"System Diagnostics:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check key services\n",
    "services_to_check = [\n",
    "    ('localhost', 5432, 'PostgreSQL'),\n",
    "    ('localhost', 6379, 'Redis'),\n",
    "    ('localhost', 4222, 'NATS'),\n",
    "    ('localhost', 8500, 'Consul'),\n",
    "    ('localhost', 8000, 'API Server'),\n",
    "    ('localhost', 3000, 'Frontend'),\n",
    "    ('localhost', 11434, 'Ollama')\n",
    "]\n",
    "\n",
    "print(\"\\nService Status:\")\n",
    "for host, port, name in services_to_check:\n",
    "    print(check_service_port(host, port, name))\n",
    "\n",
    "print(\"\\nDocker Services:\")\n",
    "print(check_docker_services())\n",
    "\n",
    "# Check environment variables\n",
    "required_vars = ['DATABASE_URL', 'REDIS_URL', 'NATS_URL', 'SECRET_KEY']\n",
    "print(\"\\nEnvironment Variables:\")\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        if 'PASSWORD' in var or 'SECRET' in var:\n",
    "            print(f\"✓ {var} is set\")\n",
    "        else:\n",
    "            print(f\"✓ {var} = {value}\")\n",
    "    else:\n",
    "        print(f\"✗ {var} is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. Database Connection Issues\n",
    "- **Problem**: Cannot connect to PostgreSQL\n",
    "- **Solution**: Ensure Docker containers are running: `docker-compose up -d postgres`\n",
    "- **Check**: Verify DATABASE_URL in .env file\n",
    "\n",
    "#### 2. Agent Communication Issues\n",
    "- **Problem**: Agents cannot communicate via NATS\n",
    "- **Solution**: Start NATS service: `docker-compose up -d nats`\n",
    "- **Check**: Verify NATS_URL configuration\n",
    "\n",
    "#### 3. Service Discovery Issues\n",
    "- **Problem**: Agents cannot register with Consul\n",
    "- **Solution**: Start Consul service: `docker-compose up -d consul`\n",
    "- **Check**: Verify CONSUL_HOST and CONSUL_PORT\n",
    "\n",
    "#### 4. Memory Issues\n",
    "- **Problem**: Services running out of memory\n",
    "- **Solution**: Increase Docker memory limits or reduce concurrent agents\n",
    "- **Check**: Monitor with `docker stats`\n",
    "\n",
    "#### 5. Port Conflicts\n",
    "- **Problem**: Ports already in use\n",
    "- **Solution**: Change ports in docker-compose.yml or stop conflicting services\n",
    "- **Check**: Use `netstat -tulpn | grep <port>`\n",
    "\n",
    "#### 6. Python Dependencies\n",
    "- **Problem**: Import errors\n",
    "- **Solution**: Install dependencies: `pip install -r requirements.txt`\n",
    "- **Check**: Use virtual environment: `python -m venv venv && source venv/bin/activate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Configuration Reference\n",
    "\n",
    "Complete list of all API keys, credentials, and configurations needed for the A2A World Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Configuration Reference\n",
    "# Display all required configurations\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration categories\n",
    "config_categories = {\n",
    "    \"Database Configuration\": {\n",
    "        \"DATABASE_URL\": \"PostgreSQL connection string (required)\",\n",
    "        \"POSTGRES_SERVER\": \"PostgreSQL host (default: localhost)\",\n",
    "        \"POSTGRES_USER\": \"Database username (default: a2a_user)\",\n",
    "        \"POSTGRES_PASSWORD\": \"Database password (required)\",\n",
    "        \"POSTGRES_DB\": \"Database name (default: a2a_world)\",\n",
    "        \"POSTGRES_PORT\": \"Database port (default: 5432)\"\n",
    "    },\n",
    "    \"Messaging & Services\": {\n",
    "        \"REDIS_URL\": \"Redis connection URL (required)\",\n",
    "        \"NATS_URL\": \"NATS messaging server URL (required)\",\n",
    "        \"CONSUL_HOST\": \"Consul service discovery host (default: localhost)\",\n",
    "        \"CONSUL_PORT\": \"Consul service discovery port (default: 8500)\",\n",
    "        \"CONSUL_TOKEN\": \"Consul ACL token (optional)\"\n",
    "    },\n",
    "    \"API Configuration\": {\n",
    "        \"SECRET_KEY\": \"JWT signing key, minimum 32 characters (required)\",\n",
    "        \"ACCESS_TOKEN_EXPIRE_MINUTES\": \"JWT token expiration (default: 10080)\",\n",
    "        \"API_V1_STR\": \"API version prefix (default: /api/v1)\",\n",
    "        \"BACKEND_CORS_ORIGINS\": \"Comma-separated CORS origins (required)\"\n",
    "    },\n",
    "    \"Frontend Configuration\": {\n",
    "        \"NEXT_PUBLIC_API_URL\": \"API URL for frontend (default: http://localhost:8000)\"\n",
    "    },\n",
    "    \"LLM Configuration\": {\n",
    "        \"OLLAMA_URL\": \"Ollama server URL (default: http://localhost:11434)\",\n",
    "        \"OLLAMA_MODEL\": \"Default Ollama model (default: llama2)\"\n",
    "    },\n",
    "    \"File Storage\": {\n",
    "        \"DATA_STORAGE_PATH\": \"Data storage directory (default: ./data)\",\n",
    "        \"MAX_FILE_SIZE_MB\": \"Maximum file size in MB (default: 100)\"\n",
    "    },\n",
    "    \"Agent System\": {\n",
    "        \"MAX_CONCURRENT_AGENTS\": \"Maximum concurrent agents (default: 10)\",\n",
    "        \"AGENT_HEARTBEAT_INTERVAL\": \"Agent heartbeat interval in seconds (default: 30)\"\n",
    "    },\n",
    "    \"Email Configuration (Optional)\": {\n",
    "        \"SMTP_HOST\": \"SMTP server host (default: smtp.gmail.com)\",\n",
    "        \"SMTP_PORT\": \"SMTP server port (default: 587)\",\n",
    "        \"SMTP_USER\": \"SMTP username\",\n",
    "        \"SMTP_PASSWORD\": \"SMTP password/app password\",\n",
    "        \"FROM_EMAIL\": \"From email address (default: noreply@a2aworld.ai)\"\n",
    "    },\n",
    "    \"Monitoring\": {\n",
    "        \"LOG_LEVEL\": \"Logging level (default: INFO)\",\n",
    "        \"PROMETHEUS_ENABLED\": \"Enable Prometheus metrics (default: true)\"\n",
    "    },\n",
    "    \"Environment\": {\n",
    "        \"ENVIRONMENT\": \"Environment mode (development/production)\",\n",
    "        \"DEBUG\": \"Debug mode (true/false)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"A2A World Platform - Complete Configuration Reference\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, configs in config_categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(\"-\" * len(category))\n",
    "    for key, description in configs.items():\n",
    "        current_value = os.getenv(key, \"\")\n",
    "        status = \"✓ Set\" if current_value else \"✗ Not set\"\n",
    "        if 'PASSWORD' in key or 'SECRET' in key or 'TOKEN' in key:\n",
    "            display_value = \"***masked***\" if current_value else \"\"\n",
    "        else:\n",
    "            display_value = current_value[:50] + \"...\" if current_value and len(current_value) > 50 else current_value\n",
    "        \n",
    "        print(f\"  {key}: {description}\")\n",
    "        print(f\"    Status: {status}\")\n",
    "        if display_value:\n",
    "            print(f\"    Current: {display_value}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\nNote: Required configurations are marked with (required) in their descriptions.\")\n",
    "print(\"Optional configurations have default values and may not need to be set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has provided a comprehensive guide to setting up and demonstrating the A2A World Platform. Here's what we've covered:\n",
    "\n",
    "### ✅ Completed Setup Steps:\n",
    "\n",
    "1. **Environment Setup**: Verified project structure and Python environment\n",
    "2. **Dependencies Installation**: Installed Python and Node.js dependencies\n",
    "3. **Configuration Guide**: Set up environment variables and validated configuration\n",
    "4. **Database Setup**: Initialized PostgreSQL with PostGIS and ran schema migrations\n",
    "5. **Agent System Demonstration**: Showed agent architecture and available agent types\n",
    "6. **Key Functionality Demos**: Demonstrated text processing, clustering, and validation\n",
    "7. **Troubleshooting**: Provided diagnostic tools and common issue solutions\n",
    "8. **Complete Configuration Reference**: Listed all required API keys and configurations\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "\n",
    "1. **Start All Services**: Run `docker-compose up -d` to start all services\n",
    "2. **Launch Agents**: Start individual agents using the provided scripts\n",
    "3. **Access Interfaces**: \n",
    "   - Frontend: http://localhost:3000\n",
    "   - API Documentation: http://localhost:8000/docs\n",
    "   - Consul Dashboard: http://localhost:8500\n",
    "   - Prometheus: http://localhost:9090\n",
    "   - Grafana: http://localhost:3001\n",
    "\n",
    "### 📚 Additional Resources:\n",
    "\n",
    "- **Documentation**: Check the `docs/` directory for detailed guides\n",
    "- **Examples**: Review example scripts in the `examples/` directory\n",
    "- **API Reference**: Visit `/docs` endpoint when API is running\n",
    "\n",
    "### 🔧 Key Services and Ports:\n",
    "\n",
    "| Service | Port | Description |\n",
    "|---------|------|-------------|\n",
    "| Frontend | 3000 | Next.js dashboard |\n",
    "| API | 8000 | FastAPI backend |\n",
    "| PostgreSQL | 5432 | Database |\n",
    "| Redis | 6379 | Caching |\n",
    "| NATS | 4222 | Agent messaging |\n",
    "| Consul | 8500 | Service discovery |\n",
    "| Ollama | 11434 | LLM inference |\n",
    "| Prometheus | 9090 | Monitoring |\n",
    "| Grafana | 3001 | Monitoring dashboard |\n",
    "\n",
    "The A2A World Platform is now ready for multidisciplinary data analysis, pattern discovery, and agent-based processing of cultural and mythological data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
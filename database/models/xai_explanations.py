"""
A2A World Platform - XAI Explanations and Narratives Models

SQLAlchemy models for storing Explainable AI explanations, narratives,
and multimodal content generated by the Narrative XAI Agent.
"""

from sqlalchemy import (
    Boolean, Column, ForeignKey, Integer, String, Text,
    DateTime, Numeric, CheckConstraint, Index
)
from sqlalchemy.dialects.postgresql import ARRAY, JSONB, UUID
from sqlalchemy.orm import relationship

from .base import Base


class XAIExplanation(Base):
    """Explainable AI explanations for patterns and decisions."""

    __tablename__ = "xai_explanations"

    pattern_id = Column(UUID(as_uuid=True), ForeignKey("patterns.id", ondelete="CASCADE"), nullable=True)
    validation_id = Column(UUID(as_uuid=True), ForeignKey("pattern_validations.id", ondelete="CASCADE"), nullable=True)
    explanation_type = Column(String(100), nullable=False)  # 'pattern_discovery', 'validation_result', 'decision_process'
    explanation_format = Column(String(50), nullable=False)  # 'text', 'narrative', 'visual', 'multimodal'
    content_type = Column(String(50))  # 'story', 'analysis', 'justification', 'recommendation'

    # Content fields
    title = Column(String(500))
    summary = Column(Text)
    full_explanation = Column(Text)
    narrative_content = Column(Text)  # Story-like explanation
    technical_details = Column(JSONB)  # Structured technical information
    visual_elements = Column(JSONB)  # Chart data, diagrams, etc.
    multimodal_content = Column(JSONB)  # Combined text, visual, audio references

    # Chain of Thought reasoning
    reasoning_steps = Column(ARRAY(JSONB))  # Array of reasoning steps
    cot_confidence = Column(Numeric(5, 4))  # Confidence in CoT reasoning
    reasoning_path = Column(ARRAY(String(255)))  # Path of reasoning steps taken

    # Metadata
    confidence_score = Column(Numeric(5, 4))
    clarity_score = Column(Numeric(5, 4))  # How clear the explanation is
    usefulness_score = Column(Numeric(5, 4))  # How useful for decision making
    audience_level = Column(String(50))  # 'expert', 'intermediate', 'general'
    language = Column(String(10), default='en')

    # Generation info
    generated_by_agent = Column(String(255), nullable=False)
    generation_method = Column(String(100))  # 'cot_reasoning', 'template_based', 'ml_generated'
    generation_parameters = Column(JSONB)
    generation_time_ms = Column(Integer)
    model_version = Column(String(100))

    # Quality and validation
    peer_reviewed = Column(Boolean, default=False)
    peer_reviewer_id = Column(String(255))
    quality_score = Column(Numeric(5, 4))
    feedback_received = Column(Text)

    # Timestamps
    created_at = Column(DateTime(timezone=True), nullable=False)
    updated_at = Column(DateTime(timezone=True))
    expires_at = Column(DateTime(timezone=True))  # For cached explanations

    # Relationships
    pattern = relationship("Pattern", back_populates="xai_explanations")
    validation = relationship("PatternValidation", back_populates="xai_explanations")
    cot_reasoning_chain = relationship("CoTReasoningChain", back_populates="explanation", cascade="all, delete-orphan")
    multimodal_elements = relationship("MultimodalElement", back_populates="explanation", cascade="all, delete-orphan")

    # Table constraints
    __table_args__ = (
        CheckConstraint("explanation_type IN ('pattern_discovery', 'validation_result', 'decision_process', 'error_explanation', 'recommendation')", name="check_explanation_type"),
        CheckConstraint("explanation_format IN ('text', 'narrative', 'visual', 'multimodal', 'interactive')", name="check_explanation_format"),
        CheckConstraint("content_type IN ('story', 'analysis', 'justification', 'recommendation', 'tutorial', 'summary')", name="check_content_type"),
        CheckConstraint("confidence_score >= 0 AND confidence_score <= 1", name="check_confidence_score"),
        CheckConstraint("clarity_score >= 0 AND clarity_score <= 1", name="check_clarity_score"),
        CheckConstraint("usefulness_score >= 0 AND usefulness_score <= 1", name="check_usefulness_score"),
        CheckConstraint("audience_level IN ('expert', 'intermediate', 'general')", name="check_audience_level"),
        CheckConstraint("quality_score >= 0 AND quality_score <= 1", name="check_quality_score"),
        Index('idx_xai_explanations_pattern', 'pattern_id'),
        Index('idx_xai_explanations_type', 'explanation_type'),
        Index('idx_xai_explanations_format', 'explanation_format'),
        Index('idx_xai_explanations_created', 'created_at'),
    )

    def __repr__(self):
        return f"<XAIExplanation(type='{self.explanation_type}', format='{self.explanation_format}', confidence={self.confidence_score})>"


class CoTReasoningChain(Base):
    """Chain of Thought reasoning steps for explainable decisions."""

    __tablename__ = "cot_reasoning_chains"

    explanation_id = Column(UUID(as_uuid=True), ForeignKey("xai_explanations.id", ondelete="CASCADE"))
    step_number = Column(Integer, nullable=False)
    step_type = Column(String(100), nullable=False)  # 'observation', 'analysis', 'inference', 'decision', 'validation'
    step_description = Column(Text, nullable=False)
    reasoning_content = Column(Text)  # The actual reasoning/thinking
    evidence_used = Column(JSONB)  # Data/evidence that led to this step
    confidence_level = Column(Numeric(5, 4))
    alternatives_considered = Column(ARRAY(Text))  # Alternative approaches considered
    uncertainty_notes = Column(Text)  # Notes about uncertainty in this step
    step_metadata = Column(JSONB)

    # Relationships
    explanation = relationship("XAIExplanation", back_populates="cot_reasoning_chain")

    # Table constraints
    __table_args__ = (
        CheckConstraint("step_type IN ('observation', 'analysis', 'inference', 'decision', 'validation', 'hypothesis', 'evidence_evaluation', 'conclusion')", name="check_step_type"),
        CheckConstraint("confidence_level >= 0 AND confidence_level <= 1", name="check_confidence_level"),
        Index('idx_cot_chain_explanation', 'explanation_id'),
        Index('idx_cot_chain_step', 'step_number'),
    )

    def __repr__(self):
        return f"<CoTReasoningChain(step={self.step_number}, type='{self.step_type}')>"


class MultimodalElement(Base):
    """Multimodal elements (charts, diagrams, images) for explanations."""

    __tablename__ = "multimodal_elements"

    explanation_id = Column(UUID(as_uuid=True), ForeignKey("xai_explanations.id", ondelete="CASCADE"))
    element_type = Column(String(50), nullable=False)  # 'chart', 'diagram', 'image', 'animation', 'interactive'
    element_format = Column(String(50))  # 'svg', 'png', 'json', 'html'
    element_title = Column(String(255))
    element_description = Column(Text)
    element_data = Column(JSONB)  # Chart data, image metadata, etc.
    element_content = Column(Text)  # Base64 encoded content or reference
    element_url = Column(String(500))  # URL to external content
    position_in_explanation = Column(Integer)  # Order in the explanation
    is_interactive = Column(Boolean, default=False)
    accessibility_description = Column(Text)  # Alt text, screen reader content

    # Relationships
    explanation = relationship("XAIExplanation", back_populates="multimodal_elements")

    # Table constraints
    __table_args__ = (
        CheckConstraint("element_type IN ('chart', 'diagram', 'image', 'map', 'timeline', 'network_graph', 'animation', 'interactive_widget')", name="check_element_type"),
        CheckConstraint("element_format IN ('svg', 'png', 'jpg', 'json', 'html', 'pdf', 'base64')", name="check_element_format"),
        Index('idx_multimodal_explanation', 'explanation_id'),
        Index('idx_multimodal_type', 'element_type'),
    )

    def __repr__(self):
        return f"<MultimodalElement(type='{self.element_type}', format='{self.element_format}')>"


class NarrativeTemplate(Base):
    """Templates for generating narrative explanations."""

    __tablename__ = "narrative_templates"

    template_name = Column(String(255), nullable=False, unique=True)
    template_type = Column(String(100), nullable=False)  # 'pattern_discovery', 'validation_result', 'error_explanation'
    audience_level = Column(String(50), default='general')
    language = Column(String(10), default='en')

    # Template structure
    template_structure = Column(JSONB)  # Template components and placeholders
    introduction_template = Column(Text)
    body_template = Column(Text)
    conclusion_template = Column(Text)
    transition_phrases = Column(ARRAY(Text))  # Phrases for connecting ideas

    # Usage statistics
    usage_count = Column(Integer, default=0)
    success_rate = Column(Numeric(5, 4))
    average_generation_time_ms = Column(Integer)
    average_quality_score = Column(Numeric(5, 4))

    # Metadata
    created_by = Column(String(255))
    created_at = Column(DateTime(timezone=True), nullable=False)
    updated_at = Column(DateTime(timezone=True))
    is_active = Column(Boolean, default=True)
    tags = Column(ARRAY(String(100)))

    # Table constraints
    __table_args__ = (
        CheckConstraint("template_type IN ('pattern_discovery', 'validation_result', 'decision_process', 'error_explanation', 'recommendation')", name="check_template_type"),
        CheckConstraint("audience_level IN ('expert', 'intermediate', 'general')", name="check_template_audience"),
        CheckConstraint("success_rate >= 0 AND success_rate <= 1", name="check_success_rate"),
        CheckConstraint("average_quality_score >= 0 AND average_quality_score <= 1", name="check_avg_quality"),
        Index('idx_narrative_templates_type', 'template_type'),
        Index('idx_narrative_templates_active', 'is_active'),
    )

    def __repr__(self):
        return f"<NarrativeTemplate(name='{self.template_name}', type='{self.template_type}')>"


class XAIRequestLog(Base):
    """Log of XAI explanation requests and responses."""

    __tablename__ = "xai_request_logs"

    request_id = Column(String(255), primary_key=True)
    agent_id = Column(String(255), nullable=False)
    request_type = Column(String(100), nullable=False)  # 'generate_explanation', 'update_narrative', 'get_cot_reasoning'
    target_type = Column(String(50))  # 'pattern', 'validation', 'decision'
    target_id = Column(String(255))

    # Request details
    request_parameters = Column(JSONB)
    request_timestamp = Column(DateTime(timezone=True), nullable=False)

    # Response details
    response_timestamp = Column(DateTime(timezone=True))
    response_status = Column(String(50))  # 'success', 'error', 'partial'
    response_explanation_id = Column(UUID(as_uuid=True), ForeignKey("xai_explanations.id"))
    processing_time_ms = Column(Integer)
    error_message = Column(Text)

    # Performance metrics
    cache_hit = Column(Boolean, default=False)
    generation_method_used = Column(String(100))
    quality_score_achieved = Column(Numeric(5, 4))

    # Relationships
    explanation = relationship("XAIExplanation")

    # Table constraints
    __table_args__ = (
        CheckConstraint("request_type IN ('generate_explanation', 'update_narrative', 'get_cot_reasoning', 'validate_explanation', 'improve_clarity')", name="check_request_type"),
        CheckConstraint("target_type IN ('pattern', 'validation', 'decision', 'error')", name="check_target_type"),
        CheckConstraint("response_status IN ('success', 'error', 'partial', 'cached')", name="check_response_status"),
        CheckConstraint("quality_score_achieved >= 0 AND quality_score_achieved <= 1", name="check_quality_achieved"),
        Index('idx_xai_requests_agent', 'agent_id'),
        Index('idx_xai_requests_timestamp', 'request_timestamp'),
        Index('idx_xai_requests_status', 'response_status'),
    )

    def __repr__(self):
        return f"<XAIRequestLog(request_id='{self.request_id}', status='{self.response_status}')>"